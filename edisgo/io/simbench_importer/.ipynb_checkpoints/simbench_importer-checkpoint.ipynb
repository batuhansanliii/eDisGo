{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import edisgo\n",
    "from edisgo import flex_opt\n",
    "from edisgo import network\n",
    "from edisgo import tools\n",
    "from edisgo import EDisGo\n",
    "from edisgo.network.grids import MVGrid, LVGrid\n",
    "from edisgo.network.timeseries import get_component_timeseries\n",
    "from edisgo.io.ding0_import import _validate_ding0_grid_import\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# from tabulate import tabulate\n",
    "# from io import StringIO\n",
    "# from pypsa import Network as PyPSANetwork\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpful debugging functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pd_print(df):\n",
    "    print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "    \n",
    "# def search_str(df,col,search_str,invert=False):\n",
    "#     if invert == False:\n",
    "#         pd_print(df.loc[df[col].str.contains(search_str)])\n",
    "#         return df.loc[df[col].str.contains(search_str)]\n",
    "#     else:\n",
    "#         pd_print(df.loc[~df[col].str.contains(search_str)])\n",
    "#         return df.loc[~df[col].str.contains(search_str)]\n",
    "    \n",
    "def search_str(df,col,search_str,invert=False):\n",
    "    if invert == False:\n",
    "        display(df.loc[df[col].str.contains(search_str)])\n",
    "    else:\n",
    "        display(df.loc[~df[col].str.contains(search_str)])\n",
    "    \n",
    "def search_str_df(df,col,search_str,invert=False):\n",
    "    if invert == False:\n",
    "        return df.loc[df[col].str.contains(search_str)]\n",
    "    else:\n",
    "        return df.loc[~df[col].str.contains(search_str)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get grid dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/heikernleong/Documents/localFiles/sa_code/edisgo/hk_edisgo/1-MVLV-comm-all-0-no_sw\n"
     ]
    }
   ],
   "source": [
    "grid_name = '1-MVLV-comm-all-0-no_sw'\n",
    "# grid_name = '1-MVLV-semiurb-3.202-1-no_sw'\n",
    "\n",
    "\n",
    "curr_path = Path.cwd()\n",
    "parent_dir = curr_path.parents[3]\n",
    "# simbench_grids_dir = parent_dir / 'simbench'\n",
    "grid_dir = parent_dir / grid_name\n",
    "print (grid_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the simbench raw data into panda dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [i for i in grid_dir.iterdir()]\n",
    "simbench_dict = {i.name[:-4]:pd.read_csv(i,delimiter=\";\") for i in file_list}\n",
    "# for i in simbench_dict.keys(): print (i)\n",
    "sb_ding0_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) buses_df (Checked for units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def label_mv_grid_id(name):\n",
    "    if \"LV\" in name:\n",
    "        return \"\"\n",
    "    elif \"MV\" in name:\n",
    "        return name[0:name.find(\" \")]\n",
    "\n",
    "def label_lv_grid_id(name):\n",
    "    if \"MV\" in name:\n",
    "        return \"\"\n",
    "    elif \"LV\" in name:\n",
    "        return name[name.find(\".\")+1:]\n",
    "    \n",
    "buses_cols_to_drop = [\n",
    "    'type',\n",
    "    'vmSetp',\n",
    "    'vaSetp',\n",
    "    'vmMin',\n",
    "    'vmMax',\n",
    "    'substation',\n",
    "    'voltLvl'\n",
    "]\n",
    "\n",
    "buses_col_location = [\n",
    "    'name',\n",
    "    'x',\n",
    "    'y',\n",
    "    'mv_grid_id',\n",
    "    'lv_grid_id',\n",
    "    'v_nom',\n",
    "    'in_building'\n",
    "]\n",
    "\n",
    "buses_df = simbench_dict['Node']\n",
    "buses_df = buses_df.rename(columns={'vmR':'v_nom'})\n",
    "buses_df = buses_df.rename(columns={'id':'name'})\n",
    "coord_df = simbench_dict['Coordinates']\n",
    "coord_df = coord_df.set_index('id')\n",
    "buses_df['x'] = buses_df['coordID'].apply(lambda coordID: coord_df.loc[coordID,'x'] )\n",
    "buses_df['y'] = buses_df['coordID'].apply(lambda coordID: coord_df.loc[coordID,'y'] )\n",
    "buses_df['in_building'] = 'False'\n",
    "\n",
    "buses_df['mv_grid_id'] =  buses_df['name'].apply(label_mv_grid_id)\n",
    "buses_df['lv_grid_id'] =  buses_df['subnet'].apply(label_lv_grid_id)\n",
    "\n",
    "# get the HV grid to adopt the mv grid id\n",
    "# hv_name = buses_df[buses_df['name'].str.contains('HV')]['name'].iloc[0]\n",
    "hv_index = buses_df.index[buses_df['name'].str.contains('HV')]\n",
    "# print (hv_index)\n",
    "mv_grid_id = buses_df[buses_df['name'].str.contains('MV')]['mv_grid_id'].iloc[0]\n",
    "buses_df.loc[hv_index,'mv_grid_id'] = mv_grid_id \n",
    "# Dropping High Voltage Bus\n",
    "buses_df = buses_df.drop(hv_index)\n",
    "\n",
    "buses_df = buses_df[buses_col_location]\n",
    "# display(buses_df.head())\n",
    "sb_ding0_dict['buses_df'] = buses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) transformer_df (No direct information on x and r. Left empty for now. Potential source of problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_rename_dict = {\n",
    "    'id':'name',\n",
    "    'nodeHV':'bus0',\n",
    "    'nodeLV':'bus1',\n",
    "}\n",
    "\n",
    "trans_col_location = [\n",
    "    'name',\n",
    "    'bus0',\n",
    "    'bus1',\n",
    "    's_nom',\n",
    "    'r',\n",
    "    'x',\n",
    "    'type_info'\n",
    "]\n",
    "\n",
    "sb_trans_df = simbench_dict['Transformer']\n",
    "sb_trans_type_df = simbench_dict['TransformerType']\n",
    "sb_trans_df = sb_trans_df.rename(columns=trans_rename_dict)\n",
    "sb_trans_type_df = sb_trans_type_df.set_index('id')\n",
    "sb_trans_df['s_nom'] = sb_trans_df['type'].apply(lambda x: sb_trans_type_df.loc[x,'sR'] )\n",
    "sb_trans_df['r'] = ''\n",
    "sb_trans_df['x'] = ''\n",
    "sb_trans_df['type_info'] = sb_trans_df['type']\n",
    "sb_trans_df = sb_trans_df[trans_col_location]\n",
    "\n",
    "transformers_hvmv_df = sb_trans_df[sb_trans_df['bus0'].str.contains('HV')]\n",
    "transformers_hvmv_df = sb_trans_df[sb_trans_df['bus1'].str.contains('MV')]\n",
    "transformers_hvmv_df = transformers_hvmv_df.set_index('name')\n",
    "\n",
    "hvmv_bus_row = transformers_hvmv_df['bus1'][0]\n",
    "transformers_hvmv_df = transformers_hvmv_df.reset_index()\n",
    "\n",
    "transformers_df = sb_trans_df[sb_trans_df['bus0'].str.contains('MV')]\n",
    "transformers_df = sb_trans_df[sb_trans_df['bus1'].str.contains('LV')]\n",
    "# transformers_df = transformers_df.set_index('name')\n",
    "\n",
    "# display(transformers_hvmv_df.head())\n",
    "# display(transformers_df.head())\n",
    "\n",
    "sb_ding0_dict['transformers_hvmv_df'] = transformers_hvmv_df\n",
    "sb_ding0_dict['transformers_df'] = transformers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) generators_df (Checked for units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "gen_col_location = [\n",
    "    'name',\n",
    "    'bus',\n",
    "    'control',\n",
    "    'p_nom',\n",
    "    'q_nom',\n",
    "    'type',\n",
    "    'weather_cell_id',\n",
    "    'subtype'\n",
    "]\n",
    "\n",
    "gen_rename_dict = {\n",
    "    'id':'name',\n",
    "    'node':'bus',\n",
    "    'pRES':'p_nom',\n",
    "    'qRES':'q_nom',\n",
    "    'profile':'weather_cell_id',\n",
    "    'calc_type':'control'\n",
    "}\n",
    "\n",
    "slack_rename_dict = {\n",
    "    'id':'name',\n",
    "    'node':'bus',\n",
    "    'calc_type':'control'\n",
    "}\n",
    "\n",
    "\n",
    "def add_slack_terms(gen_df):\n",
    "    add_gen_dict = {\n",
    "        'p_nom':0.0,\n",
    "        'q_nom':0.0,\n",
    "        'type':'station',\n",
    "        'weather_cell_id':\"\",\n",
    "        'subtype':'mv_station'\n",
    "    }\n",
    "    for key in add_gen_dict:\n",
    "        gen_df[key] = gen_df['control'].apply(lambda x: add_gen_dict[key] if x == 'Slack' else x)\n",
    "    return gen_df\n",
    "\n",
    "def change_gen_type_name(name):\n",
    "    if name =='PV' or name == 'PV_MV':\n",
    "        return 'solar'\n",
    "    elif name == 'Hydro_MV':\n",
    "        return 'hydro'\n",
    "    elif name == 'Wind_MV':\n",
    "        return 'biomass'\n",
    "    elif name == 'Biomass_MV':\n",
    "        return 'biomass'\n",
    "    else:\n",
    "        return 'unidentified'\n",
    "\n",
    "generators_df = simbench_dict['RES']\n",
    "generators_df['calc_type'] = generators_df['calc_type'].apply(lambda x: x.upper())\n",
    "generators_df = generators_df.rename(columns=gen_rename_dict)\n",
    "# generators_df['type'] = generators_df['type'].apply(lambda x: 'solar' if x == 'PV' else x.lower())\n",
    "generators_df['type'] = generators_df['type'].apply(change_gen_type_name)\n",
    "generators_df['subtype'] = generators_df['type']\n",
    "# generators_df = generators_df.drop(gen_cols_to_drop, axis = 1)\n",
    "generators_df = generators_df[gen_col_location]\n",
    "\n",
    "# display(generators_df.head())\n",
    "\n",
    "# including the slack bus\n",
    "slack_df = simbench_dict['ExternalNet']\n",
    "slack_df = slack_df.rename(columns=slack_rename_dict)\n",
    "# slack_df = slack_df.drop(slack_col_to_drop,axis=1)\n",
    "slack_df['control'] = slack_df['control'].apply(lambda x: 'Slack' if x == 'vavm' else x)\n",
    "slack_df['name'] = slack_df['name'].apply(lambda x: x+'_slack')\n",
    "slack_df = add_slack_terms(slack_df)\n",
    "slack_df = slack_df[gen_col_location] \n",
    "# display(slack_df)\n",
    "slack_df['bus'] = hvmv_bus_row\n",
    "# display(slack_df)\n",
    "# generators_df = pd.concat([slack_df,generators_df] ,ignore_index=True)\n",
    "# display (generators_df.head())\n",
    "\n",
    "sb_ding0_dict['generators_df'] = generators_df\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) lines_df (Not sure if the s_nom is line to line or 3 phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "lines_cols_to_drop = [\n",
    "    'loadingMax',\n",
    "    'subnet',\n",
    "    'voltLvl'\n",
    "]\n",
    "\n",
    "lines_col_location = [\n",
    "    'name',\n",
    "    'bus0',\n",
    "    'bus1',\n",
    "    'length',\n",
    "    'r',\n",
    "    'x',\n",
    "    's_nom',\n",
    "    'num_parallel',\n",
    "    'kind',\n",
    "    'type_info'\n",
    "]\n",
    "\n",
    "def get_line_char(lines_df, line_type_df):\n",
    "    char_dict = {\n",
    "        'r':'r',\n",
    "        'x': 'x',\n",
    "        'iMax':'iMax',\n",
    "        'kind':'type'\n",
    "    }\n",
    "    for key in char_dict:\n",
    "        lines_df[key] = lines_df['type_info'].apply(lambda x: line_type_df.loc[x,char_dict[key]])\n",
    "    return lines_df\n",
    "\n",
    "# def cal_s_nom(name):\n",
    "#     x = name['x']\n",
    "#     r = name['r']\n",
    "#     i = name['iMax']\n",
    "#     return ((((x**2 + r**2))**0.5) * (i)**2)/(10**6)\n",
    "\n",
    "def cal_s_nom(row):\n",
    "    i = row['iMax']\n",
    "    bus0 = row['bus0']\n",
    "#     print (bus0)\n",
    "    bus1 = row['bus1']\n",
    "#     print (bus1)\n",
    "#     bus0_v_nom = buses_df.loc[bus0,'v_nom']\n",
    "    bus0_v_nom = search_str_df(buses_df,'name',bus0,invert=False)['v_nom'].values[0]\n",
    "    bus1_v_nom = search_str_df(buses_df,'name',bus1,invert=False)['v_nom'].values[0]\n",
    "#     if row['bus0'] == 'MV4.101 busbar1.1':\n",
    "#         print('bus0_v_nom: '+ str(bus0_v_nom) + \"   \" + 'bus1_v_nom: '+ str(bus1_v_nom))\n",
    "    # display (bus0_v_nom)\n",
    "#     bus1_v_nom = buses_df.loc[bus1,'v_nom']\n",
    "    bus_v_nom = (bus0_v_nom+bus1_v_nom)/2 \n",
    "#     bus_v_nom = search_str_df(buses_df,'name',bus0,invert=False)['v_nom'].values[0]\n",
    "    return 3**0.5*bus_v_nom*i*10**(-3)\n",
    "#     return 3*bus_v_nom*i*10**(-3)\n",
    "\n",
    "# def mul_length(name):\n",
    "#     return name['x']*name['length']\n",
    "\n",
    "lines_df = simbench_dict['Line']\n",
    "line_type_df = simbench_dict['LineType']\n",
    "line_type_df = line_type_df.set_index('id')\n",
    "\n",
    "# pd_print(line_type_df.head())\n",
    "lines_rename_dict = {\n",
    "    'id':'name',\n",
    "    'nodeA':'bus0',\n",
    "    'nodeB':'bus1',\n",
    "    'type': 'type_info'\n",
    "}\n",
    "\n",
    "lines_df = lines_df.rename(columns=lines_rename_dict)\n",
    "# lines_df = lines_df.drop(lines_cols_to_drop,axis=1)\n",
    "lines_df = get_line_char(lines_df,line_type_df)\n",
    "lines_df['kind'] = lines_df['kind'].apply(lambda x : 'line' if x =='ohl' else x)\n",
    "lines_df['num_parallel'] = 1\n",
    "lines_df['r'] = lines_df.apply(lambda name: name['r']*name['length'],axis=1)\n",
    "lines_df['x'] = lines_df.apply(lambda name: name['x']*name['length'],axis=1)\n",
    "lines_df['s_nom'] = lines_df.apply(cal_s_nom,axis=1)\n",
    "lines_df = lines_df[lines_col_location]\n",
    "# lines_df = lines_df.set_index('name')\n",
    "# display(lines_df.head())\n",
    "\n",
    "sb_ding0_dict['lines_df'] = lines_df\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display(lines_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) loads_df (using of sR as peak load. Need to verify with Anya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "loads_rename_dict = {\n",
    "    'id':'name',\n",
    "    'node':'bus',\n",
    "    'profile': 'sector'\n",
    "}\n",
    "\n",
    "loads_cols_location = [\n",
    "    'name',\n",
    "    'bus',\n",
    "    'peak_load',\n",
    "    'annual_consumption',\n",
    "    'sector',\n",
    "    'pLoad',\n",
    "    'qLoad'\n",
    "]\n",
    "\n",
    "def cal_annual_consumption(name):\n",
    "    sR = name['sR']\n",
    "    sector = name['sector']\n",
    "    loads_profile[sector+'_sload'] = (loads_profile[ sector + '_pload']**2+loads_profile[sector + '_qload']**2)**0.5\n",
    "    annual_consumption = loads_profile[sector+'_sload'].sum()*sR\n",
    "    return annual_consumption\n",
    "\n",
    "def cal_peak_load(name):\n",
    "    sR = name['sR']\n",
    "    sector = name['sector']\n",
    "    peak_load = loads_profile[sector+'_pload'].max()*sR\n",
    "    return peak_load\n",
    "\n",
    "loads_profile = simbench_dict['LoadProfile']\n",
    "loads_df = simbench_dict['Load']\n",
    "loads_df = loads_df.rename(columns=loads_rename_dict)\n",
    "loads_df['peak_load'] = loads_df.apply(cal_peak_load,axis=1)\n",
    "loads_df['annual_consumption'] = loads_df.apply(cal_annual_consumption,axis=1)\n",
    "loads_df = loads_df[loads_cols_location]\n",
    "sb_ding0_dict['loads_df'] = loads_df\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(loads_df.sort_values(by=['peak_load'],ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) switches_df\n",
    "currently not implemented due to different means of working on the switches between the 2 systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "switch_rename_dict = {\n",
    "    'id':'name',\n",
    "    'nodeA':'bus_closed',\n",
    "    'nodeB':'bus_open',\n",
    "    'substation':'branch',\n",
    "    'type':'type_info'\n",
    "}\n",
    "\n",
    "switch_col_location = [\n",
    "    'name',\n",
    "    'bus_closed',\n",
    "    'bus_open',\n",
    "    'branch',\n",
    "    'type_info'\n",
    "]\n",
    "\n",
    "switches_df = simbench_dict['Switch']\n",
    "switches_df = switches_df.rename(columns=switch_rename_dict)\n",
    "switches_df = switches_df[switch_col_location]\n",
    "# switches_df = switches_df.set_index('name')\n",
    "\n",
    "# display(switches_df)\n",
    "\n",
    "sb_ding0_dict['switches_df'] = switches_df\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Unit\n",
    "Current implementation just includes an empty dataframe (Further implementations will include storage units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "storage_col_dict = {\n",
    "    'name': pd.Series([],dtype='str'),\n",
    "    'bus': pd.Series([],dtype='str'),\n",
    "    'control': pd.Series([],dtype='str'),\n",
    "    'p_nom': pd.Series([],dtype='float'),\n",
    "    'capacity': pd.Series([],dtype='float'),\n",
    "    'efficiency_store': pd.Series([],dtype='float'),\n",
    "    'efficiency_dispatch': pd.Series([],dtype='float'),\n",
    "}\n",
    "\n",
    "\n",
    "storage_units_df = pd.DataFrame(storage_col_dict)\n",
    "# storage_units_df =storage_units_df.set_index('name')\n",
    "# display(storage_units_df)\n",
    "sb_ding0_dict['storage_units_df'] = storage_units_df\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDisGo direct import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "edisgo_obj = EDisGo(import_timeseries=False)\n",
    "edisgo_obj.topology.buses_df = buses_df.set_index('name')\n",
    "edisgo_obj.topology.generators_df = generators_df.set_index('name')\n",
    "edisgo_obj.topology.lines_df = lines_df.set_index('name')\n",
    "edisgo_obj.topology.loads_df = loads_df.set_index('name')\n",
    "edisgo_obj.topology.switches_df = switches_df.set_index('name')\n",
    "edisgo_obj.topology.transformers_hvmv_df = transformers_hvmv_df.set_index('name')\n",
    "edisgo_obj.topology.transformers_df = transformers_df.set_index('name')\n",
    "edisgo_obj.topology.storage_units_df = storage_units_df.set_index('name')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network topology MV4.101\n",
      "Alles Gut\n"
     ]
    }
   ],
   "source": [
    "# creating the mv grid\n",
    "edisgo_obj.topology.mv_grid = MVGrid(id=mv_grid_id, edisgo_obj=edisgo_obj)\n",
    "edisgo_obj.topology._grids = {}\n",
    "edisgo_obj.topology._grids[str(edisgo_obj.topology.mv_grid)] = edisgo_obj.topology.mv_grid\n",
    "\n",
    "#creating the lv grid\n",
    "lv_grid_df =  search_str_df(buses_df,'name','LV',invert=False)\n",
    "lv_grid_ids = lv_grid_df['lv_grid_id'].unique()\n",
    "for lv_grid_id in lv_grid_ids:\n",
    "        lv_grid = LVGrid(id=lv_grid_id, edisgo_obj=edisgo_obj)\n",
    "        edisgo_obj.topology.mv_grid._lv_grids.append(lv_grid)\n",
    "        edisgo_obj.topology._grids[str(lv_grid)] = lv_grid\n",
    "\n",
    "# df = getattr(edisgo_obj.topology, \"loads\" + \"_df\")\n",
    "# print (df.bus[0])\n",
    "# missing = df.index[~df.bus.isin(edisgo_obj.topology.buses_df.index)]\n",
    "# print (\"Missing: \" + missing)\n",
    "# print (edisgo_obj.topology.buses_df.index)\n",
    "\n",
    "_validate_ding0_grid_import(edisgo_obj.topology)\n",
    "\n",
    "# get_component_timeseries(edisgo_obj=edisgo_obj, mode='worst-case')\n",
    "# get_component_timeseries(edisgo_obj=edisgo_obj, mode='worst-case-feedin')\n",
    "\n",
    "print(edisgo_obj.topology)\n",
    "print ('Alles Gut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_df = edisgo_obj.topology.generators_df.head()\n",
    "# display(gen_df[gen_df['control'].str.contains('lack')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# get_component_timeseries(edisgo_obj=edisgo_obj, mode='worst-case')\n",
    "#  Getting the time series\n",
    "load_profile_df = simbench_dict['LoadProfile']\n",
    "res_profile_df = simbench_dict['RESProfile']\n",
    "# Importing _timeindex\n",
    "timestamp_list = list(load_profile_df['time'][519:520])\n",
    "timeindex = pd.to_datetime(timestamp_list)\n",
    "edisgo_obj.timeseries._timeindex = timeindex\n",
    "load_profile_df = load_profile_df.set_index('time')\n",
    "res_profile_df = res_profile_df.set_index('time')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# getting generator time series\n",
    "def get_gen_meta_data(gen_name):\n",
    "    gen_df = search_str_df(generators_df,'name',gen_name,invert=False)\n",
    "    return {\n",
    "        'name':gen_name,\n",
    "        'p_nom':gen_df['p_nom'].values[0],\n",
    "        'q_nom':gen_df['q_nom'].values[0],\n",
    "        'wcid':gen_df['weather_cell_id'].values[0]\n",
    "    }\n",
    "\n",
    "gen_list = [ get_gen_meta_data(gen_name)  for gen_name in generators_df['name']]\n",
    "generators_active_power = pd.DataFrame(index=timeindex)\n",
    "generators_reactive_power = pd.DataFrame(index=timeindex)\n",
    "\n",
    "\n",
    "# Testing for convergence\n",
    "for gen_dict in gen_list:\n",
    "    if 'slack' not in gen_dict['name']:\n",
    "        if gen_dict['name'] == 'LV1.401 SGen 1':\n",
    "            generators_active_power[gen_dict['name']] = res_profile_df.loc[timestamp_list,gen_dict['wcid']]*gen_dict['p_nom']\n",
    "            generators_reactive_power[gen_dict['name']] = res_profile_df.loc[timestamp_list,gen_dict['wcid']]*gen_dict['q_nom']\n",
    "        else:\n",
    "            generators_active_power[gen_dict['name']] = 0.0\n",
    "            generators_reactive_power[gen_dict['name']] = 0.0\n",
    "\n",
    "\n",
    "# edisgo_obj.timeseries._generators_active_power = generators_active_power\n",
    "# edisgo_obj.timeseries._generators_reactive_power = generators_reactive_power\n",
    "# edisgo_obj.timeseries.generators_active_power = generators_active_power\n",
    "# edisgo_obj.timeseries.generators_reactive_power = generators_reactive_power\n",
    "# display(generators_active_power.head())\n",
    "# gen_active_cols = generators_active_power.columns\n",
    "# print (gen_active_cols)\n",
    "# print ('lack' in gen_active_cols)\n",
    "# display(generators_reactive_power.head())\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LV1.401 Load 1', 'LV1.401 Load 2', 'LV1.401 Load 3', 'LV1.401 Load 4',\n",
      "       'LV1.401 Load 5', 'LV1.401 Load 6', 'LV1.401 Load 7', 'LV1.401 Load 8',\n",
      "       'LV1.401 Load 9', 'LV1.401 Load 10',\n",
      "       ...\n",
      "       'MV4.101 MV Load 9', 'MV4.101 MV Load 10', 'MV4.101 MV Load 11',\n",
      "       'MV4.101 MV Load 12', 'MV4.101 MV Load 13', 'MV4.101 MV Load 14',\n",
      "       'MV4.101 MV Load 15', 'MV4.101 MV Load 16', 'MV4.101 MV Load 17',\n",
      "       'MV4.101 MV Load 18'],\n",
      "      dtype='object', length=6860)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Getting Loads time series\n",
    "def get_load_meta_data(load_name):\n",
    "    load_df = search_str_df(loads_df,'name',load_name,invert=False)\n",
    "    return {\n",
    "        'name':load_name,\n",
    "        'pLoad':load_df['pLoad'].values[0],\n",
    "        'qLoad':load_df['qLoad'].values[0],\n",
    "        'sector':load_df['sector'].values[0],\n",
    "    }\n",
    "load_list = [get_load_meta_data(load_name) for load_name in loads_df['name']]\n",
    "loads_active_power = pd.DataFrame(index=timeindex)\n",
    "loads_reactive_power = pd.DataFrame(index=timeindex)\n",
    "\n",
    "\n",
    "# Testing for convergence\n",
    "for load_dict in load_list:\n",
    "    if load_dict['name'] == 'LV1.401 Load 1':\n",
    "        loads_active_power[load_dict['name']] = load_profile_df.loc[timestamp_list,load_dict['sector']+'_pload']*load_dict['pLoad']\n",
    "        loads_reactive_power[load_dict['name']] = load_profile_df.loc[timestamp_list,load_dict['sector']+'_qload']*load_dict['qLoad']\n",
    "    else:\n",
    "        loads_active_power[load_dict['name']] = 0.0\n",
    "        loads_reactive_power[load_dict['name']] = 0.0\n",
    "\n",
    "print (loads_active_power.columns)    \n",
    "# display(loads_active_power.head())\n",
    "# display(loads_reactive_power.head())\n",
    "\n",
    "# edisgo_obj.timeseries._loads_active_power = loads_active_power\n",
    "# edisgo_obj.timeseries._loads_reactive_power = loads_reactive_power\n",
    "\n",
    "# edisgo_obj.timeseries.loads_active_power = loads_active_power\n",
    "# edisgo_obj.timeseries.loads_reactive_power = loads_reactive_power\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load other empty timeseries for other components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# edisgo_obj.timeseries._storage_units_active_power = pd.DataFrame(index=timeindex)\n",
    "# edisgo_obj.timeseries._storage_units_reactive_power = pd.DataFrame(index=timeindex)\n",
    "# edisgo_obj.timeseries._charging_points_active_power = pd.DataFrame(index=timeindex)\n",
    "# edisgo_obj.timeseries._charging_points_reactive_power = pd.DataFrame(index=timeindex)\n",
    "# edisgo_obj.timeseries._curtailment = pd.DataFrame(index=timeindex)\n",
    "\n",
    "_storage_units_active_power = pd.DataFrame(index=timeindex)\n",
    "_storage_units_reactive_power = pd.DataFrame(index=timeindex)\n",
    "_charging_points_active_power = pd.DataFrame(index=timeindex)\n",
    "_charging_points_reactive_power = pd.DataFrame(index=timeindex)\n",
    "_curtailment = pd.DataFrame(index=timeindex)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edisgo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-9057bf18fdee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpypsa_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medisgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pypsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medisgo_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage_units_active_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'edisgo' is not defined"
     ]
    }
   ],
   "source": [
    "# print(edisgo_obj.__dict__)\n",
    "# print(edisgo_obj.topology.__dict__)\n",
    "# edisgo_obj.to_graph()\n",
    "# edisgo_obj.plot_mv_grid_topology(technologies=False,node_color='technology')\n",
    "# display(edisgo_obj.timeseries.__dict__)\n",
    "# for key in edisgo_obj.timeseries.__dict__:\n",
    "#     print (key)\n",
    "# print(edisgo_obj.timeseries._timeindex)\n",
    "# display(edisgo_obj.timeseries._generators_active_power)\n",
    "# display(edisgo_obj.timeseries._generators_reactive_power)\n",
    "# get_component_timeseries(edisgo_obj=edisgo_obj, mode='manual')\n",
    "get_component_timeseries(\n",
    "    edisgo_obj=edisgo_obj,\n",
    "    mode='manual',\n",
    "#     mode='worst-case',\n",
    "    timeindex=timeindex,\n",
    "    generators_active_power=generators_active_power,\n",
    "    generators_reactive_power=generators_reactive_power,\n",
    "    loads_active_power=loads_active_power,\n",
    "    loads_reactive_power=loads_reactive_power,\n",
    "    storage_units_active_power=_storage_units_active_power,\n",
    "    storage_units_reactive_power=_storage_units_reactive_power,\n",
    "    charging_points_active_power=_charging_points_active_power,\n",
    "    charging_points_reactive_power=_charging_points_reactive_power,\n",
    "    curtailment=_curtailment\n",
    ")\n",
    "\n",
    "display(edisgo_obj.timeseries._storage_units_active_power)\n",
    "# for key in edisgo_obj.timeseries.__dict__:\n",
    "#     print (key)\n",
    "    \n",
    "for key in edisgo_obj.topology.__dict__:\n",
    "    print (key)\n",
    "    \n",
    "print(\"=============== seperator====================\")\n",
    "    \n",
    "equip_data = edisgo_obj.topology._equipment_data\n",
    "for key in equip_data:\n",
    "    print (key)\n",
    "mv_transformers = pd.DataFrame.from_dict(equip_data['mv_transformers'])\n",
    "mv_overhead_lines = pd.DataFrame.from_dict(equip_data['mv_overhead_lines'])\n",
    "mv_cables = pd.DataFrame.from_dict(equip_data['mv_cables'])\n",
    "lv_transformers = pd.DataFrame.from_dict(equip_data['lv_transformers'])\n",
    "lv_cables = pd.DataFrame.from_dict(equip_data['lv_cables'])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MV4.101 busbar1.1\n"
     ]
    }
   ],
   "source": [
    "grid = edisgo_obj.topology.mv_grid\n",
    "slack_bus = grid.transformers_df.bus1.iloc[0]\n",
    "print(slack_bus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pypsa.pf:Performing non-linear load-flow on AC sub-network SubNetwork 0 for snapshots DatetimeIndex(['2016-06-01 09:45:00', '2016-06-01 10:00:00'], dtype='datetime64[ns]', freq=None)\n",
      "INFO:pypsa.pf:Newton-Raphson solved in 0 iterations with error of nan in 0.009000 seconds\n",
      "INFO:pypsa.pf:Newton-Raphson solved in 0 iterations with error of nan in 0.008553 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Power flow analysis did not converge for thefollowing time steps: [Timestamp('2016-06-01 09:45:00'), Timestamp('2016-06-01 10:00:00')].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-178ac4146fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medisgo_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/localFiles/sa_code/edisgo/eDisGo/edisgo/edisgo.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, mode, timesteps)\u001b[0m\n\u001b[1;32m    427\u001b[0m             raise ValueError(\"Power flow analysis did not converge for the\"\n\u001b[1;32m    428\u001b[0m                              \"following time steps: {}.\".format(\n\u001b[0;32m--> 429\u001b[0;31m                 timesteps[~pf_results[\"converged\"][\"0\"]].tolist())\n\u001b[0m\u001b[1;32m    430\u001b[0m             )\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Power flow analysis did not converge for thefollowing time steps: [Timestamp('2016-06-01 09:45:00'), Timestamp('2016-06-01 10:00:00')]."
     ]
    }
   ],
   "source": [
    "edisgo_obj.analyze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_ding0_dir = parent_dir / 'sb_ding0'\n",
    "print (sb_ding0_dir)\n",
    "\n",
    "if not sb_ding0_dir.exists():\n",
    "    Path.mkdir(sb_ding0_dir)\n",
    "    \n",
    "print (sb_ding0_dict.keys())    \n",
    "    \n",
    "for key in sb_ding0_dict:\n",
    "    sb_ding0_dict[key] = sb_ding0_dict[key].set_index('name')\n",
    "    sb_ding0_dict[key].to_csv(str(sb_ding0_dir)+'/'+ key[:-3] +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_component_timeseries(edisgo_obj=edisgo_obj, mode='worst-case-feedin')\n",
    "# for key in edisgo_obj.timeseries.__dict__:\n",
    "#     print (key)\n",
    "# #     display(edisgo_obj.timeseries.__dict__[key])\n",
    "\n",
    "# print (edisgo_obj.timeseries._timeindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in edisgo_obj.timeseries.__dict__:\n",
    "#     print (key)\n",
    "#     print(type(edisgo_obj.timeseries.__dict__[key]))\n",
    "#     display(edisgo_obj.timeseries.__dict__[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in sb_ding0_dict:\n",
    "#     print (\"key: \" + key)\n",
    "#     if 'generators' or 'loads' in key:\n",
    "#         search_str(sb_ding0_dict[key],'bus','HV1 Bus 13',invert=False)\n",
    "#     elif 'lines' or 'transformers' in key:\n",
    "#         search_str(sb_ding0_dict[key],'bus0','HV1 Bus 13',invert=False)\n",
    "#         search_str(sb_ding0_dict[key],'bus1','HV1 Bus 13',invert=False)\n",
    "#     elif 'switches' in key:\n",
    "#         search_str(sb_ding0_dict[key],'bus_closed','HV1 Bus 13',invert=False)\n",
    "#         search_str(sb_ding0_dict[key],'bus_open','HV1 Bus 13',invert=False)\n",
    "\n",
    "# search_str(generators_df,'name','MV4.101 MV SGen 1',invert=False)\n",
    "# search_str(buses_df,'name','HV',invert=False)\n",
    "# search_str(buses_df,'name','MV4.101 busbar1.1',invert=False)\n",
    "# search_str(buses_df,'name','HV1 Bus 13',invert=False)\n",
    "# search_str(buses_df,'name','MV4.101 Bus 7',invert=False)\n",
    "# search_str(lines_df,'bus0','MV4.101 busbar1.1',invert=False)\n",
    "# search_str(transformers_df,'bus0','MV4.101 Bus 7',invert=False)\n",
    "# search_str(buses_df,'name','LV3.405 Bus 16',invert=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from edisgo.io.ding0_import import import_ding0_grid, _validate_ding0_grid_import\n",
    "\n",
    "# curr_path = Path.cwd()\n",
    "# parent = curr_path.parents[3]\n",
    "# sb_ding0_dir = parent / 'sb_ding0'\n",
    "# ding0_dir = parent / 'ding0_test_network'\n",
    "\n",
    "# search_str(generators_df,'name','HV1 grid at MV4.101_slack',invert=False)\n",
    "# search_str(buses_df,'name','HV1 Bus 13',invert=False)\n",
    "\n",
    "# edisgo_obj = EDisGo(import_timeseries=False)\n",
    "# print ('Hey')\n",
    "# import_ding0_grid(sb_ding0_dir, edisgo_obj)\n",
    "# print ('Hey Kern')\n",
    "# # _validate_ding0_grid_import(edisgo_obj.topology)\n",
    "\n",
    "\n",
    "\n",
    "# # edisgo_obj.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:edisgo]",
   "language": "python",
   "name": "conda-env-edisgo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
